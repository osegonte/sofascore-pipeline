#!/bin/bash
# cleanup_project.sh - Remove unnecessary files and keep only essentials

echo "ðŸ§¹ Cleaning Up SofaScore Pipeline Project"
echo "=========================================="

# Create backup directory for removed files
mkdir -p removed_files_backup

echo "ðŸ“¦ Moving unnecessary files to backup..."

# Remove old scraper scripts (keep only the working live_scraper.py)
if [ -f "src/late_goal/continuous_monitor.py" ]; then
    mv "src/late_goal/continuous_monitor.py" removed_files_backup/
    echo "  âœ… Moved continuous_monitor.py"
fi

if [ -f "src/late_goal/dashboard.py" ]; then
    mv "src/late_goal/dashboard.py" removed_files_backup/
    echo "  âœ… Moved dashboard.py"
fi

if [ -f "src/late_goal/data_collector.py" ]; then
    mv "src/late_goal/data_collector.py" removed_files_backup/
    echo "  âœ… Moved data_collector.py"
fi

if [ -f "src/late_goal/data_verifier.py" ]; then
    mv "src/late_goal/data_verifier.py" removed_files_backup/
    echo "  âœ… Moved data_verifier.py"
fi

if [ -f "standalone_collector.py" ]; then
    mv "standalone_collector.py" removed_files_backup/
    echo "  âœ… Moved standalone_collector.py"
fi

if [ -f "run_late_goal_collection.py" ]; then
    mv "run_late_goal_collection.py" removed_files_backup/
    echo "  âœ… Moved run_late_goal_collection.py"
fi

if [ -f "setup_late_goal.py" ]; then
    mv "setup_late_goal.py" removed_files_backup/
    echo "  âœ… Moved setup_late_goal.py"
fi

# Remove entire late_goal directory if empty
if [ -d "src/late_goal" ] && [ -z "$(ls -A src/late_goal)" ]; then
    rmdir "src/late_goal"
    echo "  âœ… Removed empty late_goal directory"
fi

# Remove duplicate/old database scripts
if [ -f "database/csv_import.py" ]; then
    mv "database/csv_import.py" removed_files_backup/
    echo "  âœ… Moved csv_import.py (replaced by simpler version)"
fi

if [ -f "database/data_viewer.py" ]; then
    mv "database/data_viewer.py" removed_files_backup/
    echo "  âœ… Moved data_viewer.py"
fi

if [ -f "database/unified_data_creator.py" ]; then
    mv "database/unified_data_creator.py" removed_files_backup/
    echo "  âœ… Moved unified_data_creator.py"
fi

if [ -f "database/validate_data_quality.py" ]; then
    mv "database/validate_data_quality.py" removed_files_backup/
    echo "  âœ… Moved validate_data_quality.py"
fi

# Remove test files (keep only essential ones)
if [ -d "tests" ]; then
    mv tests removed_files_backup/
    echo "  âœ… Moved tests directory"
fi

# Remove backup files
if [ -f "src/live_scraper.py.backup" ]; then
    mv "src/live_scraper.py.backup" removed_files_backup/
    echo "  âœ… Moved backup files"
fi

# Remove old scripts that are no longer needed
for script in fix_issues.sh make_scripts_executable.sh update_scraper.sh test_scraper.sh; do
    if [ -f "$script" ]; then
        mv "$script" removed_files_backup/
        echo "  âœ… Moved $script"
    fi
done

# Keep only essential shell scripts
echo ""
echo "ðŸ“‹ ESSENTIAL FILES KEPT:"
echo "========================"

echo "ðŸ Python Files:"
echo "  â€¢ src/live_scraper.py              (Main data collector)"
echo "  â€¢ src/utils.py                     (Utility functions)"
echo "  â€¢ src/fixture_scraper.py           (Future fixtures)"
echo "  â€¢ src/historical_scraper.py        (Historical data)"
echo "  â€¢ config/database.py               (Database connection)"
echo "  â€¢ config/config.py                 (Configuration)"

echo ""
echo "ðŸ“ Shell Scripts:"
ls -la *.sh 2>/dev/null | while read line; do
    filename=$(echo "$line" | awk '{print $9}')
    if [ "$filename" != "." ] && [ "$filename" != ".." ] && [ -f "$filename" ]; then
        case "$filename" in
            "setup_environment.sh") echo "  â€¢ $filename         (Initial setup)" ;;
            "start_live_scraper.sh") echo "  â€¢ $filename        (Start data collection)" ;;
            "stop_live_scraper.sh") echo "  â€¢ $filename         (Stop collection)" ;;
            "monitor_scraper.sh") echo "  â€¢ $filename          (Monitor status)" ;;
            "view_data.sh") echo "  â€¢ $filename              (View collected data)" ;;
            "validate_data.sh") echo "  â€¢ $filename           (Validate data quality)" ;;
            "cleanup_project.sh") echo "  â€¢ $filename         (This cleanup script)" ;;
        esac
    fi
done

echo ""
echo "ðŸ“Š Data Directories:"
echo "  â€¢ exports/                         (CSV output files)"
echo "  â€¢ logs/                            (Application logs)"
echo "  â€¢ database/                        (Database scripts)"

echo ""
echo "ðŸ“¦ Configuration:"
echo "  â€¢ requirements.txt                 (Python dependencies)"
echo "  â€¢ .gitignore                       (Git ignore rules)"
echo "  â€¢ README.md                        (Documentation)"

# Create a simple project structure overview
cat > PROJECT_STRUCTURE.md << 'EOF'
# SofaScore Live Data Scraper - Project Structure

## ðŸŽ¯ Purpose
Collects live football match statistics from SofaScore API with minute-by-minute data export.

## ðŸš€ Quick Start
```bash
./setup_environment.sh    # First-time setup
./start_live_scraper.sh    # Start collecting data
./monitor_scraper.sh       # Monitor in another terminal
./stop_live_scraper.sh     # Stop collection
```

## ðŸ“ Project Structure
```
sofascore-pipeline/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ live_scraper.py         # Main data collector
â”‚   â”œâ”€â”€ utils.py                # Helper functions
â”‚   â”œâ”€â”€ fixture_scraper.py      # Future fixtures
â”‚   â””â”€â”€ historical_scraper.py   # Historical data
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ database.py             # Database connection
â”‚   â””â”€â”€ config.py               # Configuration
â”œâ”€â”€ exports/                    # CSV output files
â”œâ”€â”€ logs/                       # Application logs
â”œâ”€â”€ *.sh                        # Shell scripts for operation
â””â”€â”€ requirements.txt            # Python dependencies
```

## ðŸ“Š Data Output
- **File Format**: `exports/live_match_minutes_complete_YYYYMMDD_HHMMSS.csv`
- **Collection**: Every 5 minutes during live matches
- **Export**: Every 15 minutes
- **Statistics**: Ball possession, shots, passes, fouls, corners, cards, etc.

## ðŸ”§ Configuration
- Collects from up to 5 live matches per cycle
- 1.5 second delay between API requests
- Automatic error handling and retry logic
- Graceful shutdown with Ctrl+C

## ðŸ“ˆ Monitoring
Use `./monitor_scraper.sh` to see:
- Current live matches
- Collection status
- Recent exports
- Error logs
EOF

echo ""
echo "âœ… CLEANUP COMPLETED!"
echo "ðŸ“¦ Removed files backed up to: removed_files_backup/"
echo "ðŸ“„ Created PROJECT_STRUCTURE.md for reference"
echo ""
echo "ðŸŽ¯ STREAMLINED PROJECT READY!"
echo "   â€¢ Essential files only"
echo "   â€¢ Clean directory structure"
echo "   â€¢ Working live data collection"
echo ""
echo "ðŸš€ Your scraper is currently running and collecting data!"
echo "ðŸ“Š Check exports/ directory for CSV files every 15 minutes"